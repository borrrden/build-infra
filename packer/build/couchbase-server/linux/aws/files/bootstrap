#!/bin/bash -e

# This script is called via userdata on the instance by way of the cloud config
# in jenkins and runs at every boot so the ephemeral volumes can be provisioned
# and docker can start up once complete
#
# Any changes made to this script should be made on the understanding that
# it will be triggered on every boot. It touches /.booted at the end
# so if you want to do something only on first boot, check for that file.

set -x
set +e

positional_params=()
while [[ $# -gt 0 ]]; do
  key="$1"

  case $key in
    --timezone)
      timezone="$2"
      shift
      shift
      ;;
    --ssh-pubkey)
      ssh_pubkey="$2"
      shift
      shift
      ;;
    *)
      positional_params+=("$1")
      shift
      ;;
  esac
done

environment="${environment:-${positional_params[0]}}"
service="${service:-${positional_params[1]}}"
timezone="${timezone:-America/Los_Angeles}"

function set_timezone() {
  # Configures timezone, should only run on first boot
  if [ ! -f /.booted ]
  then
    sed -i '/.*ZONE.*/c\ZONE="${timezone}"' /etc/sysconfig/clock
    mv /etc/localtime /etc/localtime.org
    ln -sf /usr/share/zoneinfo/${timezone} /etc/localtime
    echo "${timezone}" > /etc/timezone
  fi
}

function create_var_lib_docker() {
  # If we don't have a (non-root) persistent EBS volume, put /var/lib/docker
  # on the instance store volume
  if [ ! -L /dev/persistent/disk1 ]
  then
    docker_disk="ephemeral"
  else
    docker_disk="persistent"
  fi

  # switcheroo /var/lib/docker if currently unswitcherooed
  if [ ! -d /${docker_disk}/var/lib/docker ]
  then
    rm -rf /var/lib/docker
    mkdir -p /${docker_disk}/var/lib/docker
    ln -s /${docker_disk}/var/lib/docker/ /var/lib/docker
  fi
  mkdir -p /var/lib/docker/cb-home
}

function update_fstab() {
  for disk in ephemeral persistent
  do
    if ! grep ${disk} /etc/fstab
    then
      if [ -L "/dev/${disk}/disk1" ]
      then
        mkdir -p /${disk}
        echo "/dev/${disk}/disk1 /${disk} ext4 defaults,nofail,discard 0 2" >> /etc/fstab
      fi
    fi
  done
}

function get_stackfile() {
  declare -A stackfiles
  stackfiles["analytics"]="analytics/analytics-jenkins-agents.yml"
  stackfiles["cv"]="cv/cv-jenkins-agents.yml"
  stackfiles["server"]="couchbase-server/server-jenkins-buildslaves.yml"

  curl -fLo /opt/buildteam/stackfile.yml "https://raw.githubusercontent.com/couchbase/build-infra/master/docker-stacks/${stackfiles[${environment}]}"
}

function provision_disk() {
  if lsblk -o NAME,FSTYPE -dsn | grep ${1}n1
  then
    if nvme list | grep ${1} | grep "Elastic Block Store"
    then
      name=persistent # EBS volume
    else
      name=ephemeral  # Instance volume
    fi

    # We need to ensure the ephemeral storage is configured at each boot, we'll
    # skip persistent vol if it already exists though
    if ! lvs | grep ${name}
    then
      DISKSIZE_STRING=$(lsblk | grep "${1}n1" | awk '{print $4}')
      case $DISKSIZE_STRING in
        *G)
          DISK_UNIT=G
          ;;
        *T)
          DISK_UNIT=T
          ;;
      esac
      DISKSIZE_RAW=$(echo $DISKSIZE_STRING | cut -f1 -d$DISK_UNIT)

      if [ $DISK_UNIT = "G" ]
      then
        DISKSIZE_RAW=$(echo "scale=4; $DISKSIZE_RAW-0.1" | bc)
      else
        DISKSIZE_RAW=$(echo "scale=4; $DISKSIZE_RAW-0.001" | bc)
      fi

      pvcreate /dev/${1}n1
      vgcreate ${name} /dev/${1}n1
      # lvcreate seems to exit a split second before the disk is ready sometimes,
      # we need to create the filesystem after a short delay to work around this.
      lvcreate --name disk1 --size ${DISKSIZE_RAW}${DISK_UNIT} ${name}
      sleep 2
      mkfs.ext4 /dev/${name}/disk1
    fi
  fi
}

function get_agent_secrets() {
  # Get the names of the secrets we want from parameter store
  secrets=$(aws ssm --region $(</opt/buildteam/region) describe-parameters --parameter-filters "Key=tag:Consumer,Values=jenkins-worker" "Key=tag:Environment,Values=${environment},shared" | jq -r ".Parameters[].Name")

  for secret in ${secrets}
  do
      echo "Reading $secret"
      # We're composing filenames from parameters like: jenkins-worker__server__.ssh__config
      # where each __ is replaced with a / to construct the path.
      #
      # The first two components of the path specify what the parameter's purpose isÂ and the
      # environment it belongs to, with environment always being either ${environment} or
      # 'shared.' We know everything we're reading here belongs to this container though, so
      # we can just strip out the leading jenkins-worker/${environment}/ and use whatever
      # remains as the path.
      #
      # e.g:
      #   jenkins-worker__server__.ssh__config = [/var/lib/docker/cb-home/].ssh/config
      #   jenkins-worker__shared__.ssh__authorized_keys = [/var/lib/docker/cb-home/].ssh/authorized_keys
      secret_path="/var/lib/docker/cb-home$(echo ${secret} | sed -e"s/__/\//g;s/^jenkins-worker\/[^\/]*//g")"
      mkdir -p $(dirname $secret_path)
      aws ssm get-parameter --region $(</opt/buildteam/region) --with-decryption --name ${secret} | jq -r ".Parameter.Value" > "${secret_path}"
  done
  chown -R 1000:1000 /var/lib/docker/cb-home
}

function get_host_secrets() {
  # This all works the same as the agent secrets above (minus container-specific parts)
  secrets=$(aws ssm --region $(</opt/buildteam/region) describe-parameters --parameter-filters "Key=tag:Consumer,Values=jenkins-worker" "Key=tag:Environment,Values=host" | jq -r ".Parameters[].Name")

  for secret in ${secrets}
  do
      echo "Reading $secret"
      secret_path="/root$(echo ${secret} | sed -e"s/__/\//g;s/^jenkins-worker\/[^\/]*//g")"
      mkdir -p $(dirname $secret_path)
      aws ssm get-parameter --region $(</opt/buildteam/region) --with-decryption --name ${secret} | jq -r ".Parameter.Value" > "${secret_path}"
  done
}

function docker_run_args() {
  # Compile args we'll be passing to `docker run`
  args="--rm --name worker --pull always -v /etc/timezone:/etc/timezone:ro -v /etc/localtime:/etc/localtime:ro -v /tmp/aws:/aws -v /var/lib/docker/cb-home:/home/couchbase:rw -v /ephemeral/jenkins:/home/couchbase/jenkins -d -p 4000:22 "
  if [ "${environment}" = "cv" ]
  then
    args="${args}-v /opt/buildteam/hooks/cv-hook.sh:/usr/sbin/couchhook.d/cv-hook.sh "
  fi

  # Mount docker socket for analytics builders
  if [ "${environment}" = "analytics" ]
  then
      args="${args}-v /var/run/docker.sock:/var/run/docker.sock "
  fi
  echo "${args}"
}

function ecr_login() {
  # Login so we can pull images from ECR
  aws_acct=$(aws sts get-caller-identity | jq -r ".Account")
  aws ecr get-login-password --region $(</opt/buildteam/region) | docker login --username AWS --password-stdin ${aws_acct}.dkr.ecr.$(</opt/buildteam/region).amazonaws.com
}

function container_image() {
  get_stackfile
  # Determine container image for specified service
  if [ "${environment}" = "cv" ]
  then
    # CV nodes use swarm-launcher, we need to grab the image from an environment var
    yq e ".services.${service}.environment.LAUNCH_IMAGE" /opt/buildteam/stackfile.yml
  else
    yq e ".services.${service}.image" /opt/buildteam/stackfile.yml
  fi
}

# Configure timezone based on --timezone flag (or use America/Los_Angeles if not provided)
set_timezone

# Provision disks...
# I don't know if the EBS/persistent devices can be different from one
# instance to the next. We just call with the device names here and
# figure out what they are via `nvme list` in provision_disk()
#
# Note: there's an assumption here that we're on a <= 8xlarge instance type
# with a single (non-OS) EBS volume, and thus only have 2 disks to consider.
provision_disk nvme1
provision_disk nvme2

# More basic disk stuff
update_fstab
mount -a
create_var_lib_docker

set -e
# Start docker in the background so we can move on to retrieving secrets
# straight away
# Note: We don't set the docker service to come up automatically at boot,
# because we need to ensure the disks are ready before the container
# comes up (and we don't set the container to come up automatically because
# we want to ensure we're running from the current image in the stackfile)
service docker start &

# Get secrets from parameter store
get_agent_secrets
get_host_secrets

# If we're passing in an ssh key (for self service), ensure it's present in container's authorized_keys
[ "${ssh_pubkey}" != "" ] \
  && mkdir -p "/var/lib/docker/cb-home/.ssh/" \
  && echo "${ssh_pubkey}" >> /var/lib/docker/cb-home/.ssh/authorized_keys

# wait for docker to finish coming up
while [ ! -f /var/run/docker.pid ]
do
  echo "Waiting for docker to start"
  sleep 1
done

# Authenticate for pulling images from ECR
ecr_login

# Run build container
docker run $(docker_run_args) $(container_image) default

# Allow this script to run at next boot
rm /var/lib/cloud/instances/*/sem/config_scripts_user

touch /.booted
